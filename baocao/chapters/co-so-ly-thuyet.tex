\documentclass[../thesis.tex]{subfiles}

\begin{document}

\section{Convolutional Neural Networks}

\subsection{Khái niệm Convolutional Neural Network}

Convolutional Neural Network (CNN) là một kiến trúc mạng neurons giả định trước rằng dữ liệu đầu vào là dữ liệu ảnh, cho phép trích xuất các thuộc tính nhất định trong dữ liệu ảnh đó. Điều này khiến cho việc tính toán trở nên hiệu quả và giảm đáng kể số lượng tham số trong mạng \cite{cs231n}.

Không giống như các mạng neurons thông thường, các lớp của CNN gồm các neurons có dạng ma trận 3 chiều: chiều rộng (width), chiều cao (height), chiều sâu (depth). Có thể thấy rằng, các neurons trong một lớp chỉ kết nối với một vùng nhỏ của lớp phía trước nó \cite{cs231n}.
\begin{figure}[H]
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=.74\linewidth]{neural_net2.jpeg}
		\caption{Mạng neurons thông thường}\label{Fig:NN}
	\end{minipage}\hfill
	\begin {minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\linewidth]{cnn.jpeg}
		\caption{Convolutional Neural Network}\label{Fig:CNN}
	\end{minipage}
\end{figure}

\subsection{Kiến trúc cơ bản của CNN}

Các mô hình CNN cơ bản thường bắt đầu bằng một lớp convolutional và kết thúc bằng một (vài) lớp fully-connected. Ở giữa là các lớp convolutional và pooling để tăng hiệu quả trích xuất các đặc trưng.

\begin{itemize}
  \begin{item}
	Lớp convolutional: là thành phần quan trọng nhất trong CNN. Mỗi neuron ở lớp này được xem như là một cửa sổ trượt, trượt trên ma trận đầu vào và thực hiện tính toán giá trị tích vô hướng tại mỗi vị trí mà cửa sổ này trượt qua. Các tham số quan trọng ở layer này là kernel size, padding (p) và stride (s). Kernel size là kích thước của cửa sổ trượt, được định nghĩa bằng chiều rộng (w), chiều cao (h) và chiều sâu (d) – chính là số neurons trong layer. Chiều rộng và chiều cao phải nhỏ hơn hoặc bằng chiều rộng (w*) và chiều cao (h*) của ma trận đầu vào. Stride định nghĩa khoảng cách của mỗi bước trượt, trong khi padding quyết định xem bao nhiêu dữ liệu 0 được chèn vào rìa của ma trận đầu vào. Kích thước đầu ra là $W \times H \times d$ với $W = \displaystyle\frac{w^*-w+2p}{s}+1$ và $H = \displaystyle\frac{h^*-h+2p}{s}+1$. Lớp convolutional thường sử dụng hàm kích hoạt ReLU cho feature map đầu ra.
	\begin{figure}[H]
		\centering
		\includegraphics[width=\linewidth]{ActivationMap.png}
		\caption{Activation Map\cite{adeshpande3cnn1}}\label{activation_map}
	\end{figure}
  \end{item}
  
  \begin{item}
  Lớp pooling: thường nằm sau một convolutional layer để làm giảm kích cỡ cũng như các dữ liệu dư thừa của feature map. Một thuật toán pooling thường được sử dụng là max pooling. Max pooling sử dụng cửa sổ trượt trượt không trùng lắp qua ma trận đầu vào và chọn ra giá trị lớn nhất nằm trong cửa sổ để xây dựng ma trận đầu ra.
  \begin{figure}[H]
		\centering
		\includegraphics[width=\linewidth]{max_pooling.png}
		\caption{Max pooling}\label{max_pooling}
	\end{figure}
  \end{item} 
  \begin{item}
  Lớp dense (fully-connected): Thường thì có ít nhất 2 lớp dense nằm ở cuối cùng của mô hình CNN. Các lớp dense phía trước có nhiệm vụ làm phẳng (flatten) feature map trong khi lớp cuối cùng thực hiện việc predict bằng một mô hình regression.
  \end{item}
\end{itemize}

\begin{figure}[H]
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=.82\linewidth]{depthcol.jpeg}
		\caption{Một lớp convolutional}\label{Fig:depthcol}
	\end{minipage}\hfill
	\begin {minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\linewidth]{neuron_model.jpeg}
		\caption{Một neuron trong CNN}\label{Fig:neural_model}
	\end{minipage}
\end{figure}

\section{Region-based Convolutional Neural Networks}

Region-based Convolutional Neural Networks (R-CNN) là một mô hình nhận dạng vật thể (object detection model) do Ross Girshick, Jeff Donahue, Trevor Darrell và Jitendra Malik (UC Berkeley) đề xuất. Ý tưởng mô hình là với mỗi dữ liệu đầu vào, thực hiện trích xuất (extract) region proposals, trích xuất vector đặc trưng cho mỗi region, từ đó tiến hành việc phân lớp. Giai đoạn cuối cùng là hiệu chỉnh lại tọa độ của các regions bằng một mô hình linear regression đơn giản.

\begin{figure}[H]
	\centering
	\includegraphics[width=\linewidth]{rcnn.PNG}
	\caption{Kiến trúc của R-CNN}\label{Fig:rcnn}
\end{figure}

\subsection{Selective search}

Kết hợp thế mạnh của Exhaustive search và Segmentation, Selective search giúp định vị vị trí của vật thể trong dữ liệu ảnh một cách hiệu quả. Đầu tiên, tập R gồm các initial regions được khởi tạo. Tiếp đến, tính độ tương đồng (similarity) giữa các cặp regions láng giềng. Các cặp regions tương tự nhau nhất sẽ được gộp lại, đồng thời độ tương đồng sẽ được làm mới. Quá trình lặp đi lặp lại cho đến khi dữ liệu ảnh chỉ còn một region duy nhất.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\linewidth]{selective-search.PNG}
	\caption{Pseudocode của selective search}\label{Fig:selective_search}
\end{figure}

Selective search được sử dụng trong giai đoạn trích xuất region proposals của mô hình R-CNN. Với mỗi dữ liệu ảnh, giải thuật thực hiện khoanh vùng 2000 regions làm cơ sở cho việc trích xuất vector đặc trưng.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\linewidth]{rcnn_extract_reigions.PNG}
	\caption{Extract regions trong R-CNN}\label{Fig:rcnn_extract_regions}
\end{figure}

\subsection{Feature extraction}

Mỗi region sẽ được truyền thẳng (feed forward) qua một mạng CNN với nhiều lớp convolutional, pooling và fully-connected. Vector đặc trưng sẽ được tính toán ra ở lớp fully-connected gần với lớp output nhất.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\linewidth]{features_extraction.PNG}
	\caption{Features extraction trong R-CNN}\label{Fig:rcnn_features_extraction}
\end{figure}

Để việc trích xuất đặc trưng có hiệu quả tốt, mạng CNN được huấn luyện với một tập dữ liệu lớn, sau đó thực hiện fine-tuning bằng các mẫu dữ liệu positive và negative được phân loại từ các regions. Những regions có tỷ lệ IoU\footnote{Intersection over union} với ground-truth box $\geq$ 0.5 sẽ được tính là positive, còn lại là negative.

\subsection{SVM classifiers}

Bộ phân lớp SVM có nhiệm vụ gắn nhãn cho các regions. Việc huấn luyện các mô hình SVM diễn ra tương đối đơn giản:

\begin{itemize}
	\item Tạo các mẫu dữ liệu positive và negative. Positive được lấy từ ground-truth box, còn negative là các region có tỷ lệ IoU với ground-truth box < 0.3.
	\item Chọn ra các negative “khó” bằng phương pháp hard negative mining. Việc này giúp giảm bớt số lượng mẫu negative, đồng thời tăng hiệu quả huấn luyện.
	\item Tiến hành huấn luyện mô hình trên tập positive và negative. Tập dữ liệu trước tiên sẽ được trích xuất đặc trưng thông qua mạng CNN.
\end{itemize}

Ở giai đoạn prediction, vector đặc trưng sẽ đi qua các bộ phân lớp SVM, từ đó nhãn tương ứng sẽ được gán.

\subsection{Bounding-box regression}

Sau khi đã phân lớp xong, vector đặc trưng được truyền qua một mô hình hồi quy tuyến tính để hiệu chỉnh vị trí của bounding-box. Hàm lỗi của mô hình được định nghĩa như sau:

$L(W) = \displaystyle\frac{1}{2N}\displaystyle\sum_{N}^{}\|Y - W^TF\|^2 + \frac{1}{2}\lambda\|W\|^2$

với $Y = 
\begin{bmatrix}
	\displaystyle\frac{G_x - P_x}{P_w}; & \displaystyle\frac{G_y - P_y}{P_h}; & \log\left(\displaystyle\frac{G_w}{P_w}\right); & \log\left(\displaystyle\frac{G_h}{P_h}\right)
\end{bmatrix}
$

\textit{Trong đó $P = \left[P_x; P_y; P_w; P_h\right]$ là ma trận tọa độ tâm và kích thước của region, tương tự với ground-truth box $G = \left[G_x; G_y; G_w; G_h\right]$. $F$ là ma trận các vector đặc trưng được trích xuất từ các region.}

Predicted output sẽ được chuyển ngược lại thành tọa độ và kích thước. 

\section{Fast R-CNN}

% TODO: Bổ sung phần này
Fast R-CNN là một phiên bản cải tiến của R-CNN. Fast R-CNN nhận vào cả nội dung của ảnh và một tập các region proposals của ảnh đó, dữ liệu ảnh được feed forward qua một số lớp convolutional và max pooling tạo ra feature map. Sau đó, với mỗi object proposal, một lớp region of interest (RoI) pooling được sử dụng để trích xuất feature vector từ feature map. Mỗi feature vector lại tiếp tục được feed forward qua các lớp fully-connected tạo ra một RoI feature vector rồi cuối cùng được chia thành hai nhánh: một nhánh softmax dùng để dự báo là các vật thể thuộc lớp (class) nào, nhánh còn lại cho biết vị trí của các bounding-box chứa các vật thể đó. Kiến trúc của Fast R-CNN như hình \ref{Fig:fastrcnn}.

\begin{figure}[H]
	\centering
	\includegraphics[width=\linewidth]{fast-rcnn-arch.png}
	\caption{Kiến trúc của Fast R-CNN}\label{Fig:fastrcnn}
\end{figure}

\subsection{Lớp RoI pooling}

Lớp RoI pooling được sử dụng để chuyển đổi các đặc trưng trên một ảnh thực sự sang feature map với kích thước bé hơn $(H \times W)$. Mỗi một RoI được định nghĩa bởi 4 tham số $(r, c, h, w)$ biểu diễn cho góc trên bên trái $(r, c)$ và chiều cao, chiều rộng $(h, w)$.

\subsection{Multi-task loss}

Như đã trình bày ở trên, Fast R-CNN có 2 lớp đầu ra: một dùng để tính xác suất xem vật thể được phát hiện thuộc lớp (class) nào trong $K+1$ lớp (K loại vật thể và 1 cho phần nền), $p = (p_0,\ldots, p_K)$, một dùng để tính toán vị trí của bounding-box $t^k = \left(t^k_x, t^k_y, t^k_w, t^k_h\right)$.

Mỗi RoI trong tập train được gán nhãn với một ground-truth class là $u$ và ground-truth bounding-box là $v$. Hàm lỗi $L$ được tính như sau:

$L\left(p, u, t^u, v\right) = L_{cls}\left(p, u\right) + \lambda\left[u\geq1\right]L_{loc}\left(t^u, v\right)$

với $L_{cls}\left(p, u\right) = -\log p_u$ là hàm mất mát $\log$ cho lớp đúng $u$.

Hàm mất mát $L_{loc}$ định nghĩa dựa trên bounding-box đúng (nhãn) trên tập dữ liệu $u, v = \left(v_x, v_y, v_w, v_h\right)$  và bounding-box được dự đoán bởi mô hình $t^u = \left(t^u_x, t^u_y, t^u_w, t^u_h\right)$ (trên lớp $u$). Biểu thức $\left[u \geq 1\right]$ có giá trị là 1 khi $u \geq 1$ và ngược lại có giá trị là 0.


\section{Faster R-CNN}

Fast R-CNN cải thiện thời gian thực thi và không gian lưu trữ bằng cách chia sẻ tính toán đối với hàng nghìn regions. Tuy nhiên vẫn còn một tồn tại, đó là sự nghẽn cổ chai giữa quá trình trích xuất RoI và quá trình RoI Pooling. Các RoI được tạo ra bằng giải thuật Selective search, vốn không tận dụng được sức mạnh xử lý của GPU. Để giải quyết vấn đề trên, mô hình Faster R-CNN ra đời. Thay vì dùng các giải thuật truyền thống để trích xuất region proposals, Faster R-CNN thiết kế một mô hình CNN với tên gọi Region Proposal Network để thực hiện điều này.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\linewidth]{faster-rcnn.PNG}
	\caption{Faster R-CNN}\label{Fig:faster_rcnn}
\end{figure}

\subsection{Region Proposal Network}

Region Proposal Network (RPN) nhận đầu vào là feature map của dữ liệu ảnh và xuất ra một tập các region proposals chứa các thông tin về nhãn và vị trí. Có thể hình dung RPN như một cửa sổ trượt. Cửa sổ này trượt qua từng location có kích thước  trên feature map và tính toán ra vector đặc trưng. Vector này được feed forward vào hai lớp fully-connected để dự đoán nhãn và vị trí.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\linewidth]{rpn.PNG}
	\caption{Region Proposal Network}\label{Fig:rpn}
\end{figure}

\subsection{Anchor}

Tại mỗi vị trí, có $k$ anchor được tạo ra. Mỗi anchor được định nghĩa bởi tâm của vị trí, scale và aspect ratio. Mặc định có 3 scale và 3 aspect ratio nên , tức là có 9 anchors (các anchors này cùng có chung một tâm).

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\linewidth]{anchors.PNG}
	\caption{Anchors}\label{Fig:anchors}
\end{figure}

\subsection{Loss function}

Mỗi anchor sẽ được gắn nhãn là 1 (positive) hoặc 0 (negative) tùy thuộc vào tỷ lệ IoU giữa nó và ground-truth box. Tập positive bao gồm những anchors có tỷ lệ IoU với một ground-truth box là lớn nhất hoặc tỷ lệ IoU với bất kỳ ground-truth box lớn hơn 0.7. Tập negative chứa những anchors có tỷ lệ IoU với tất cả ground-truth box nhỏ hơn 0.3.

Hàm mất mát được định nghĩa như sau: 

$L(\{p_i\}, t\{t_i\}) = \displaystyle\frac{1}{N_{cls}}\displaystyle\sum_{i}^{} L_{cls}(p_i, p_i^*)+\lambda\displaystyle\frac{1}{N_{reg}}\displaystyle\sum_{i}^{}p_i^*L_{reg}(t_i,t_i^*)$

với $L_{cls}(p_i, p_i^*) = -p_i^*\log{p_i} - (1 - p_i^*)\log{(1-p_i)}$

và $L_{reg}(t_i,t_i^*) = 
\begin{cases}
    0.5\|t_i - t_i^*\|^2	& \quad \text{nếu }\|t_i - t_i^*\| < 1\\
    \|t_i - t_i^*\| - 0.5  	& \quad \text{các trường hợp còn lại}
\end{cases}
$

\textit{Trong đó $p_i$ là xác xuất để anchor thứ $i$ chứa vật thể, $p^*_i$ là nhãn của anchor, $t_i$ và $t^*_i$ là vector 4 chiều chứa vị trí của predicted box và positive anchor.}

\end{document}